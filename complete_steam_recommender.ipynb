{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad19c20",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9987f62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully!\n",
      "✓ Device: mps\n",
      "✓ PyTorch version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "from scipy.sparse import load_npz, csr_matrix, lil_matrix, save_npz\n",
    "from scipy import stats\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization setup\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available() else \n",
    "    \"cuda\" if torch.cuda.is_available() else \n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"✓ Libraries imported successfully!\")\n",
    "print(f\"✓ Device: {device}\")\n",
    "print(f\"✓ PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e727a661",
   "metadata": {},
   "source": [
    "## 2. Load Pre-computed Features\n",
    "\n",
    "This section loads all features that were computed in the feature engineering phase:\n",
    "- User-item interaction matrix\n",
    "- Bundle-game mapping matrix\n",
    "- Game similarity matrices (bundle-based, co-purchase, combined)\n",
    "- Bundle similarity matrix\n",
    "- ID mappings (user, item, bundle)\n",
    "- Game popularity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aaf7dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING PRE-COMPUTED FEATURES\n",
      "======================================================================\n",
      "✓ User-item matrix: (70912, 10978), nnz=5,094,082\n",
      "✓ Bundle-game matrix: (613, 10978), nnz=1,834\n",
      "✓ Game similarity (bundle): (10978, 10978)\n",
      "✓ Game similarity (copurchase): (10978, 10978)\n",
      "✓ Game similarity (combined): (10978, 10978)\n",
      "✓ Bundle similarity: (613, 613)\n",
      "✓ Mappings loaded: 70,912 users, 10,978 items, 613 bundles\n",
      "✓ Game popularity scores loaded\n",
      "\n",
      "======================================================================\n",
      "ALL FEATURES LOADED SUCCESSFULLY!\n",
      "======================================================================\n",
      "✓ User-item matrix: (70912, 10978), nnz=5,094,082\n",
      "✓ Bundle-game matrix: (613, 10978), nnz=1,834\n",
      "✓ Game similarity (bundle): (10978, 10978)\n",
      "✓ Game similarity (copurchase): (10978, 10978)\n",
      "✓ Game similarity (combined): (10978, 10978)\n",
      "✓ Bundle similarity: (613, 613)\n",
      "✓ Mappings loaded: 70,912 users, 10,978 items, 613 bundles\n",
      "✓ Game popularity scores loaded\n",
      "\n",
      "======================================================================\n",
      "ALL FEATURES LOADED SUCCESSFULLY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"LOADING PRE-COMPUTED FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "features_dir = './features'\n",
    "\n",
    "# Load sparse matrices\n",
    "user_item_matrix = load_npz(f'{features_dir}/user_item_matrix.npz')\n",
    "bundle_game_matrix = load_npz(f'{features_dir}/bundle_game_matrix.npz')\n",
    "game_similarity_bundle = load_npz(f'{features_dir}/game_similarity_bundle.npz')\n",
    "game_similarity_copurchase = load_npz(f'{features_dir}/game_similarity_copurchase.npz')\n",
    "game_similarity_combined = load_npz(f'{features_dir}/game_similarity_combined.npz')\n",
    "bundle_similarity_matrix = np.load(f'{features_dir}/bundle_similarity_matrix.npy')\n",
    "\n",
    "print(f\"✓ User-item matrix: {user_item_matrix.shape}, nnz={user_item_matrix.nnz:,}\")\n",
    "print(f\"✓ Bundle-game matrix: {bundle_game_matrix.shape}, nnz={bundle_game_matrix.nnz:,}\")\n",
    "print(f\"✓ Game similarity (bundle): {game_similarity_bundle.shape}\")\n",
    "print(f\"✓ Game similarity (copurchase): {game_similarity_copurchase.shape}\")\n",
    "print(f\"✓ Game similarity (combined): {game_similarity_combined.shape}\")\n",
    "print(f\"✓ Bundle similarity: {bundle_similarity_matrix.shape}\")\n",
    "\n",
    "# Load mappings\n",
    "with open(f'{features_dir}/mappings.pkl', 'rb') as f:\n",
    "    mappings = pickle.load(f)\n",
    "    user_to_idx = mappings['user_to_idx']\n",
    "    idx_to_user = mappings['idx_to_user']\n",
    "    item_to_idx = mappings['item_to_idx']\n",
    "    idx_to_item = mappings['idx_to_item']\n",
    "    bundle_to_idx = mappings['bundle_to_idx']\n",
    "    idx_to_bundle = mappings['idx_to_bundle']\n",
    "\n",
    "print(f\"✓ Mappings loaded: {len(user_to_idx):,} users, {len(item_to_idx):,} items, {len(bundle_to_idx):,} bundles\")\n",
    "\n",
    "# Load game popularity\n",
    "game_popularity_df = pd.read_csv(f'{features_dir}/game_popularity.csv')\n",
    "popularity_scores = game_popularity_df.sort_values('item_idx')['popularity_score'].values\n",
    "\n",
    "print(f\"✓ Game popularity scores loaded\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL FEATURES LOADED SUCCESSFULLY!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2a71e6",
   "metadata": {},
   "source": [
    "## 3. Load Train-Test Split\n",
    "\n",
    "If train-test split already exists, load it. Otherwise, create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be9e4fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING EXISTING TRAIN-TEST SPLIT\n",
      "======================================================================\n",
      "✓ Train matrix loaded: (70912, 10978), nnz=4,103,384\n",
      "✓ Test set loaded: 990,698 user-item pairs\n",
      "✓ Test users: 62,936\n",
      "\n",
      "======================================================================\n",
      "TRAIN-TEST SPLIT READY!\n",
      "======================================================================\n",
      "✓ Train matrix loaded: (70912, 10978), nnz=4,103,384\n",
      "✓ Test set loaded: 990,698 user-item pairs\n",
      "✓ Test users: 62,936\n",
      "\n",
      "======================================================================\n",
      "TRAIN-TEST SPLIT READY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "model_outputs_dir = './model_outputs'\n",
    "os.makedirs(model_outputs_dir, exist_ok=True)\n",
    "\n",
    "# Check if train/test split exists\n",
    "train_matrix_path = f'{model_outputs_dir}/train_matrix.npz'\n",
    "test_set_path = f'{model_outputs_dir}/test_set.csv'\n",
    "\n",
    "if os.path.exists(train_matrix_path) and os.path.exists(test_set_path):\n",
    "    print(\"=\" * 70)\n",
    "    print(\"LOADING EXISTING TRAIN-TEST SPLIT\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    train_matrix = load_npz(train_matrix_path)\n",
    "    test_df = pd.read_csv(test_set_path)\n",
    "    \n",
    "    print(f\"✓ Train matrix loaded: {train_matrix.shape}, nnz={train_matrix.nnz:,}\")\n",
    "    print(f\"✓ Test set loaded: {len(test_df):,} user-item pairs\")\n",
    "    print(f\"✓ Test users: {test_df['user_idx'].nunique():,}\")\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"CREATING TRAIN-TEST SPLIT\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Create train-test split (hold out 20% of each user's items)\n",
    "    train_matrix = user_item_matrix.tolil()\n",
    "    test_data = []\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_users = user_item_matrix.shape[0]\n",
    "    \n",
    "    for user_idx in range(n_users):\n",
    "        if user_idx % 10000 == 0:\n",
    "            print(f\"  Processing user {user_idx}/{n_users}...\")\n",
    "        \n",
    "        user_items = user_item_matrix[user_idx].nonzero()[1]\n",
    "        \n",
    "        if len(user_items) < 5:  # Need at least 5 items for meaningful split\n",
    "            continue\n",
    "        \n",
    "        # Hold out 20% for testing\n",
    "        n_test = max(1, int(len(user_items) * 0.2))\n",
    "        test_items = np.random.choice(user_items, size=n_test, replace=False)\n",
    "        \n",
    "        # Store test data\n",
    "        for item_idx in test_items:\n",
    "            test_data.append({\n",
    "                'user_idx': user_idx,\n",
    "                'item_idx': item_idx,\n",
    "                'user_id': idx_to_user[user_idx],\n",
    "                'item_id': idx_to_item[item_idx]\n",
    "            })\n",
    "            # Remove from training\n",
    "            train_matrix[user_idx, item_idx] = 0\n",
    "    \n",
    "    # Convert back to CSR for efficient operations\n",
    "    train_matrix = train_matrix.tocsr()\n",
    "    test_df = pd.DataFrame(test_data)\n",
    "    \n",
    "    # Save for future use\n",
    "    save_npz(train_matrix_path, train_matrix)\n",
    "    test_df.to_csv(test_set_path, index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Train matrix: {train_matrix.shape}, nnz={train_matrix.nnz:,}\")\n",
    "    print(f\"✓ Test set: {len(test_df):,} user-item pairs\")\n",
    "    print(f\"✓ Test users: {test_df['user_idx'].nunique():,}\")\n",
    "    print(f\"✓ Saved to {model_outputs_dir}/\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAIN-TEST SPLIT READY!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b74dd71",
   "metadata": {},
   "source": [
    "## 4. Model Definitions\n",
    "\n",
    "Here we define all three recommender models with GPU acceleration support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7f2bf",
   "metadata": {},
   "source": [
    "### 4.1 Task 1: Next-Game Purchase Prediction\n",
    "\n",
    "**NextGameRecommender** - Hybrid model combining:\n",
    "- Item-based collaborative filtering\n",
    "- Bundle-enhanced similarity\n",
    "- Popularity baseline for cold-start users\n",
    "- GPU acceleration with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e968d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ NextGameRecommender class defined\n"
     ]
    }
   ],
   "source": [
    "class NextGameRecommender:\n",
    "    \"\"\"\n",
    "    Hybrid recommender for predicting next-game purchases.\n",
    "    Combines collaborative filtering, bundle-enhanced similarity, and popularity.\n",
    "    \n",
    "    Best parameters (from tuning):\n",
    "    - alpha=0.7 (70% similarity weight, 30% popularity weight)\n",
    "    - similarity_matrix=game_similarity_combined\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, train_matrix, similarity_matrix, popularity_scores, alpha=0.7,\n",
    "                 device=None, densify_similarity_auto_cap_bytes=1_000_000_000):\n",
    "        self.train_matrix = train_matrix\n",
    "        self.similarity_matrix = similarity_matrix\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # Set device (GPU if available)\n",
    "        self.device = torch.device(device) if device is not None else (\n",
    "            torch.device(\"mps\") if torch.backends.mps.is_available() else\n",
    "            torch.device(\"cuda\") if torch.cuda.is_available() else\n",
    "            torch.device(\"cpu\")\n",
    "        )\n",
    "        \n",
    "        # Move popularity scores to GPU\n",
    "        pop = torch.as_tensor(popularity_scores, dtype=torch.float32)\n",
    "        self.popularity_t = pop.flatten().to(self.device)\n",
    "        self.n_items = int(self.popularity_t.numel())\n",
    "        \n",
    "        # Try to keep similarity matrix on GPU if feasible\n",
    "        self.similarity_t = None\n",
    "        if torch.is_tensor(similarity_matrix):\n",
    "            self.similarity_t = similarity_matrix.to(self.device, dtype=torch.float32)\n",
    "        elif isinstance(similarity_matrix, np.ndarray):\n",
    "            self.similarity_t = torch.from_numpy(similarity_matrix).to(self.device, dtype=torch.float32)\n",
    "        else:\n",
    "            # Sparse matrix - densify only if small enough\n",
    "            shape = getattr(similarity_matrix, \"shape\", None)\n",
    "            if shape is not None and len(shape) == 2 and shape[0] == shape[1]:\n",
    "                est_bytes = int(shape[0]) * int(shape[1]) * 4  # float32\n",
    "                if self.device.type != \"cpu\" and est_bytes <= densify_similarity_auto_cap_bytes:\n",
    "                    dense = similarity_matrix.toarray() if hasattr(similarity_matrix, \"toarray\") else np.asarray(similarity_matrix)\n",
    "                    self.similarity_t = torch.from_numpy(dense).to(self.device, dtype=torch.float32)\n",
    "    \n",
    "    def recommend(self, user_idx, k=10, exclude_owned=True):\n",
    "        \"\"\"\n",
    "        Generate top-K recommendations for a user.\n",
    "        \n",
    "        Args:\n",
    "            user_idx: User index\n",
    "            k: Number of recommendations\n",
    "            exclude_owned: Whether to exclude already owned items\n",
    "            \n",
    "        Returns:\n",
    "            List of (item_idx, score) tuples\n",
    "        \"\"\"\n",
    "        k = int(min(k, self.n_items))\n",
    "        \n",
    "        # Get user's owned items\n",
    "        user_items = self.train_matrix[user_idx].nonzero()[1]\n",
    "        \n",
    "        # Cold start: return popular items\n",
    "        if len(user_items) == 0:\n",
    "            top_vals, top_idx = torch.topk(self.popularity_t, k)\n",
    "            return [(int(i), float(v)) for i, v in zip(top_idx.tolist(), top_vals.tolist())]\n",
    "        \n",
    "        # Compute similarity scores\n",
    "        if self.similarity_t is not None:\n",
    "            # GPU-accelerated similarity computation\n",
    "            user_items_t = torch.tensor(user_items, device=self.device, dtype=torch.long)\n",
    "            scores_t = self.similarity_t.index_select(0, user_items_t).sum(dim=0)\n",
    "            scores_t = scores_t / float(len(user_items))\n",
    "        else:\n",
    "            # CPU sparse computation\n",
    "            user_profile = self.train_matrix[user_idx].copy()\n",
    "            user_profile.data = np.ones_like(user_profile.data)  # Binarize\n",
    "            \n",
    "            cpu_scores = user_profile.dot(self.similarity_matrix)\n",
    "            if hasattr(cpu_scores, \"toarray\"):\n",
    "                scores_np = cpu_scores.toarray().ravel()\n",
    "            else:\n",
    "                scores_np = np.asarray(cpu_scores).ravel()\n",
    "            \n",
    "            scores_np = scores_np / float(len(user_items))\n",
    "            scores_t = torch.from_numpy(scores_np).to(self.device, dtype=torch.float32)\n",
    "        \n",
    "        # Combine with popularity (on GPU)\n",
    "        combined_scores_t = self.alpha * scores_t + (1 - self.alpha) * self.popularity_t\n",
    "        \n",
    "        # Exclude already owned items\n",
    "        if exclude_owned:\n",
    "            user_items_t = torch.tensor(user_items, device=self.device, dtype=torch.long)\n",
    "            combined_scores_t.index_fill_(0, user_items_t, float(\"-inf\"))\n",
    "        \n",
    "        # Get top-K on GPU\n",
    "        top_vals, top_idx = torch.topk(combined_scores_t, k)\n",
    "        \n",
    "        return [(int(i), float(v)) for i, v in zip(top_idx.tolist(), top_vals.tolist())]\n",
    "\n",
    "print(\"✓ NextGameRecommender class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4818359",
   "metadata": {},
   "source": [
    "### 4.2 Task 2: Bundle Completion Recommender\n",
    "\n",
    "**BundleCompletionRecommender** - Recommends missing games from partially owned bundles.\n",
    "Prioritizes bundles with high ownership ratios (e.g., owns 3/5 games → recommend remaining 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb3c2cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ BundleCompletionRecommender class defined\n"
     ]
    }
   ],
   "source": [
    "class BundleCompletionRecommender:\n",
    "    \"\"\"\n",
    "    Recommends games to complete partially owned bundles.\n",
    "    \n",
    "    Key insight: Partial bundle ownership is a strong purchase signal.\n",
    "    Users who own 2/5 games in a bundle are likely to purchase the remaining 3.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, user_item_matrix, bundle_game_matrix, idx_to_item, item_to_idx):\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.bundle_game_matrix = bundle_game_matrix\n",
    "        self.idx_to_item = idx_to_item\n",
    "        self.item_to_idx = item_to_idx\n",
    "    \n",
    "    def get_partial_bundles(self, user_idx):\n",
    "        \"\"\"\n",
    "        Find bundles that user partially owns.\n",
    "        \n",
    "        Returns:\n",
    "            List of dicts with bundle info and ownership ratios\n",
    "        \"\"\"\n",
    "        user_games = set(self.user_item_matrix[user_idx].nonzero()[1])\n",
    "        user_game_ids = {self.idx_to_item[idx] for idx in user_games}\n",
    "        \n",
    "        partial_bundles = []\n",
    "        n_bundles = self.bundle_game_matrix.shape[0]\n",
    "        \n",
    "        for bundle_idx in range(n_bundles):\n",
    "            bundle_game_indices = self.bundle_game_matrix[bundle_idx].nonzero()[1]\n",
    "            bundle_game_ids = {self.idx_to_item[idx] for idx in bundle_game_indices}\n",
    "            \n",
    "            if not bundle_game_ids:\n",
    "                continue\n",
    "            \n",
    "            owned = user_game_ids & bundle_game_ids\n",
    "            missing = bundle_game_ids - user_game_ids\n",
    "            \n",
    "            ownership_ratio = len(owned) / len(bundle_game_ids)\n",
    "            \n",
    "            # Only consider partial ownership (not 0% or 100%)\n",
    "            if 0 < ownership_ratio < 1:\n",
    "                missing_indices = [self.item_to_idx[gid] for gid in missing if gid in self.item_to_idx]\n",
    "                partial_bundles.append({\n",
    "                    'bundle_idx': bundle_idx,\n",
    "                    'ownership_ratio': ownership_ratio,\n",
    "                    'owned_count': len(owned),\n",
    "                    'missing_count': len(missing),\n",
    "                    'missing_games': missing,\n",
    "                    'missing_indices': missing_indices\n",
    "                })\n",
    "        \n",
    "        return sorted(partial_bundles, key=lambda x: x['ownership_ratio'], reverse=True)\n",
    "    \n",
    "    def recommend(self, user_idx, k=10, min_ownership=0.3):\n",
    "        \"\"\"\n",
    "        Recommend games from partially owned bundles.\n",
    "        \n",
    "        Args:\n",
    "            user_idx: User index\n",
    "            k: Number of recommendations\n",
    "            min_ownership: Minimum ownership ratio to consider (default 30%)\n",
    "            \n",
    "        Returns:\n",
    "            List of (item_idx, confidence_score) tuples\n",
    "        \"\"\"\n",
    "        partial_bundles = self.get_partial_bundles(user_idx)\n",
    "        \n",
    "        # Score missing games by bundle ownership ratio\n",
    "        game_scores = defaultdict(float)\n",
    "        \n",
    "        for bundle in partial_bundles:\n",
    "            if bundle['ownership_ratio'] >= min_ownership:\n",
    "                score = bundle['ownership_ratio']\n",
    "                for item_idx in bundle['missing_indices']:\n",
    "                    game_scores[item_idx] = max(game_scores[item_idx], score)\n",
    "        \n",
    "        # Sort by score and return top-K\n",
    "        recommendations = sorted(game_scores.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "print(\"✓ BundleCompletionRecommender class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a2bbc3",
   "metadata": {},
   "source": [
    "### 4.3 Task 3: Cross-Bundle Discovery Recommender\n",
    "\n",
    "**CrossBundleRecommender** - Discovers similar bundles based on content and user overlap.\n",
    "Useful for cross-promotion: \"If you liked Bundle A, try Bundle B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d0c99bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CrossBundleRecommender class defined\n"
     ]
    }
   ],
   "source": [
    "class CrossBundleRecommender:\n",
    "    \"\"\"\n",
    "    Discovers similar bundles based on bundle-bundle similarity.\n",
    "    \n",
    "    Uses cosine similarity of bundle game compositions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, bundle_similarity_matrix, idx_to_bundle):\n",
    "        self.bundle_similarity_matrix = bundle_similarity_matrix\n",
    "        self.idx_to_bundle = idx_to_bundle\n",
    "    \n",
    "    def recommend(self, bundle_idx, k=5, min_similarity=0.1):\n",
    "        \"\"\"\n",
    "        Recommend similar bundles.\n",
    "        \n",
    "        Args:\n",
    "            bundle_idx: Source bundle index\n",
    "            k: Number of recommendations\n",
    "            min_similarity: Minimum similarity threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of dicts with bundle info and similarity scores\n",
    "        \"\"\"\n",
    "        # Get similarities for this bundle\n",
    "        similarities = self.bundle_similarity_matrix[bundle_idx].copy()\n",
    "        similarities[bundle_idx] = 0  # Exclude self\n",
    "        \n",
    "        # Filter by minimum similarity\n",
    "        valid_indices = np.where(similarities >= min_similarity)[0]\n",
    "        valid_similarities = similarities[valid_indices]\n",
    "        \n",
    "        # Sort and get top-K\n",
    "        top_k_indices = valid_indices[np.argsort(-valid_similarities)][:k]\n",
    "        \n",
    "        recommendations = []\n",
    "        for idx in top_k_indices:\n",
    "            recommendations.append({\n",
    "                'bundle_idx': int(idx),\n",
    "                'bundle_id': self.idx_to_bundle.get(int(idx)),\n",
    "                'similarity': float(similarities[idx])\n",
    "            })\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "print(\"✓ CrossBundleRecommender class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88ea0d9",
   "metadata": {},
   "source": [
    "## 5. Initialize Best Models\n",
    "\n",
    "Based on comprehensive evaluation, we initialize the best performing models with optimal parameters:\n",
    "- **Combined similarity** (60% bundle + 40% co-purchase)\n",
    "- **Alpha = 0.7** (70% similarity weight, 30% popularity weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "183ca5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INITIALIZING BEST MODELS\n",
      "======================================================================\n",
      "✓ Task 1 - NextGameRecommender initialized (alpha=0.7, device=mps)\n",
      "✓ Task 2 - BundleCompletionRecommender initialized\n",
      "✓ Task 3 - CrossBundleRecommender initialized\n",
      "\n",
      "======================================================================\n",
      "ALL MODELS READY FOR RECOMMENDATIONS!\n",
      "======================================================================\n",
      "✓ Task 1 - NextGameRecommender initialized (alpha=0.7, device=mps)\n",
      "✓ Task 2 - BundleCompletionRecommender initialized\n",
      "✓ Task 3 - CrossBundleRecommender initialized\n",
      "\n",
      "======================================================================\n",
      "ALL MODELS READY FOR RECOMMENDATIONS!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"INITIALIZING BEST MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Task 1: Next-Game Purchase Prediction (Combined model with alpha=0.7)\n",
    "next_game_recommender = NextGameRecommender(\n",
    "    train_matrix=train_matrix,\n",
    "    similarity_matrix=game_similarity_combined,\n",
    "    popularity_scores=popularity_scores,\n",
    "    alpha=0.7,\n",
    "    device=device\n",
    ")\n",
    "print(f\"✓ Task 1 - NextGameRecommender initialized (alpha=0.7, device={device})\")\n",
    "\n",
    "# Task 2: Bundle Completion\n",
    "bundle_completion_recommender = BundleCompletionRecommender(\n",
    "    user_item_matrix=train_matrix,\n",
    "    bundle_game_matrix=bundle_game_matrix,\n",
    "    idx_to_item=idx_to_item,\n",
    "    item_to_idx=item_to_idx\n",
    ")\n",
    "print(f\"✓ Task 2 - BundleCompletionRecommender initialized\")\n",
    "\n",
    "# Task 3: Cross-Bundle Discovery\n",
    "cross_bundle_recommender = CrossBundleRecommender(\n",
    "    bundle_similarity_matrix=bundle_similarity_matrix,\n",
    "    idx_to_bundle=idx_to_bundle\n",
    ")\n",
    "print(f\"✓ Task 3 - CrossBundleRecommender initialized\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL MODELS READY FOR RECOMMENDATIONS!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aecc02",
   "metadata": {},
   "source": [
    "## 6. Evaluation Functions\n",
    "\n",
    "Define comprehensive evaluation functions with confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e996adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def ndcg_at_k(true_items, predicted_items, k):\n",
    "    \"\"\"Calculate NDCG@K for a single user.\"\"\"\n",
    "    dcg = sum(1.0 / np.log2(i + 2) for i, item in enumerate(predicted_items[:k]) if item in true_items)\n",
    "    idcg = sum(1.0 / np.log2(i + 2) for i in range(min(len(true_items), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def evaluate_next_game_recommender(recommender, test_df, k_values=[5, 10, 20], max_users=None):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation for next-game recommender.\n",
    "    \n",
    "    Metrics:\n",
    "    - Precision@K: Fraction of recommended items that are relevant\n",
    "    - Recall@K: Fraction of relevant items that are recommended\n",
    "    - Hit Rate@K: Whether at least one relevant item was recommended\n",
    "    - NDCG@K: Normalized Discounted Cumulative Gain (ranking quality)\n",
    "    \"\"\"\n",
    "    test_grouped = test_df.groupby('user_idx')['item_idx'].apply(set).to_dict()\n",
    "    users_to_eval = list(test_grouped.keys())[:max_users]\n",
    "    \n",
    "    raw_results = {k: defaultdict(list) for k in k_values}\n",
    "    max_k = max(k_values)\n",
    "    \n",
    "    print(f\"Evaluating on {len(users_to_eval):,} users...\")\n",
    "    \n",
    "    for i, user_idx in enumerate(users_to_eval):\n",
    "        if i > 0 and i % 5000 == 0:\n",
    "            print(f\"  Progress: {i:,}/{len(users_to_eval):,} users...\")\n",
    "        \n",
    "        true_items = test_grouped[user_idx]\n",
    "        if not true_items:\n",
    "            continue\n",
    "        \n",
    "        recs = recommender.recommend(user_idx, k=max_k)\n",
    "        rec_indices = [item_idx for item_idx, score in recs]\n",
    "        \n",
    "        for k in k_values:\n",
    "            k_recs = rec_indices[:k]\n",
    "            hits = len(true_items & set(k_recs))\n",
    "            raw_results[k]['precision'].append(hits / k if k > 0 else 0)\n",
    "            raw_results[k]['recall'].append(hits / len(true_items))\n",
    "            raw_results[k]['hit_rate'].append(1 if hits > 0 else 0)\n",
    "            raw_results[k]['ndcg'].append(ndcg_at_k(true_items, k_recs, k))\n",
    "    \n",
    "    # Calculate mean and confidence intervals\n",
    "    summary = {}\n",
    "    for k, metrics in raw_results.items():\n",
    "        summary[k] = {}\n",
    "        for metric, scores in metrics.items():\n",
    "            if not scores:\n",
    "                continue\n",
    "            mean = np.mean(scores)\n",
    "            sem = stats.sem(scores)\n",
    "            ci = sem * stats.t.ppf(0.975, len(scores) - 1) if len(scores) > 1 else 0\n",
    "            summary[k][metric] = {'mean': mean, 'ci': ci}\n",
    "    \n",
    "    return summary, raw_results\n",
    "\n",
    "def evaluate_bundle_completion(recommender, test_df, k_values=[5, 10, 20]):\n",
    "    \"\"\"\n",
    "    Evaluate bundle completion recommender.\n",
    "    \n",
    "    Metrics:\n",
    "    - Hit Rate@K: Whether recommended items were actually purchased\n",
    "    - Bundle Precision@K: Fraction of recommendations from partial bundles\n",
    "    \"\"\"\n",
    "    actual_by_user = test_df.groupby('user_idx')['item_idx'].apply(set).to_dict()\n",
    "    test_users = list(actual_by_user.keys())\n",
    "    \n",
    "    raw_results = {k: defaultdict(list) for k in k_values}\n",
    "    users_with_partial_bundles = 0\n",
    "    max_k = max(k_values)\n",
    "    \n",
    "    print(f\"Evaluating on {len(test_users):,} users...\")\n",
    "    \n",
    "    for i, user_idx in enumerate(test_users):\n",
    "        if i > 0 and i % 5000 == 0:\n",
    "            print(f\"  Progress: {i:,}/{len(test_users):,} users...\")\n",
    "        \n",
    "        partial_bundles = recommender.get_partial_bundles(user_idx)\n",
    "        if not partial_bundles:\n",
    "            continue\n",
    "        \n",
    "        users_with_partial_bundles += 1\n",
    "        recs = recommender.recommend(user_idx, k=max_k, min_ownership=0.3)\n",
    "        if not recs:\n",
    "            continue\n",
    "        \n",
    "        rec_indices = [item_idx for item_idx, score in recs]\n",
    "        actual_items = actual_by_user.get(user_idx, set())\n",
    "        \n",
    "        all_missing_indices = {idx for bundle in partial_bundles for idx in bundle['missing_indices']}\n",
    "        \n",
    "        for k in k_values:\n",
    "            k_recs_set = set(rec_indices[:k])\n",
    "            hits = len(actual_items & k_recs_set)\n",
    "            raw_results[k]['precision'].append(hits / k if k > 0 else 0)\n",
    "            raw_results[k]['hit_rate'].append(1 if hits > 0 else 0)\n",
    "            raw_results[k]['bundle_precision'].append(len(k_recs_set & all_missing_indices) / k if k > 0 else 0)\n",
    "    \n",
    "    print(f\"✓ Evaluated on {users_with_partial_bundles:,} users with partial bundles\")\n",
    "    \n",
    "    summary = {}\n",
    "    for k, metrics in raw_results.items():\n",
    "        summary[k] = {}\n",
    "        for metric, scores in metrics.items():\n",
    "            if not scores:\n",
    "                continue\n",
    "            mean = np.mean(scores)\n",
    "            sem = stats.sem(scores)\n",
    "            ci = sem * stats.t.ppf(0.975, len(scores) - 1) if len(scores) > 1 else 0\n",
    "            summary[k][metric] = {'mean': mean, 'ci': ci}\n",
    "    \n",
    "    return summary, raw_results\n",
    "\n",
    "print(\"✓ Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044159cc",
   "metadata": {},
   "source": [
    "## 7. Run Comprehensive Evaluation\n",
    "\n",
    "Evaluate all models on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf240522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPREHENSIVE EVALUATION\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "TASK 1: NEXT-GAME PURCHASE PREDICTION\n",
      "======================================================================\n",
      "Evaluating on 62,936 users...\n",
      "Evaluating on 62,936 users...\n",
      "  Progress: 5,000/62,936 users...\n",
      "  Progress: 5,000/62,936 users...\n",
      "  Progress: 10,000/62,936 users...\n",
      "  Progress: 10,000/62,936 users...\n",
      "  Progress: 15,000/62,936 users...\n",
      "  Progress: 15,000/62,936 users...\n",
      "  Progress: 20,000/62,936 users...\n",
      "  Progress: 20,000/62,936 users...\n",
      "  Progress: 25,000/62,936 users...\n",
      "  Progress: 25,000/62,936 users...\n",
      "  Progress: 30,000/62,936 users...\n",
      "  Progress: 30,000/62,936 users...\n",
      "  Progress: 35,000/62,936 users...\n",
      "  Progress: 35,000/62,936 users...\n",
      "  Progress: 40,000/62,936 users...\n",
      "  Progress: 40,000/62,936 users...\n",
      "  Progress: 45,000/62,936 users...\n",
      "  Progress: 45,000/62,936 users...\n",
      "  Progress: 50,000/62,936 users...\n",
      "  Progress: 50,000/62,936 users...\n",
      "  Progress: 55,000/62,936 users...\n",
      "  Progress: 55,000/62,936 users...\n",
      "  Progress: 60,000/62,936 users...\n",
      "  Progress: 60,000/62,936 users...\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RESULTS:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "K = 5:\n",
      "  Precision@5: 0.2424 ± 0.0018\n",
      "  Recall@5   : 0.1421 ± 0.0016\n",
      "  Hit Rate@5 : 0.6817 ± 0.0036\n",
      "  NDCG@5     : 0.3032 ± 0.0022\n",
      "\n",
      "K = 10:\n",
      "  Precision@10: 0.1864 ± 0.0012\n",
      "  Recall@10   : 0.2085 ± 0.0018\n",
      "  Hit Rate@10 : 0.7945 ± 0.0032\n",
      "  NDCG@10     : 0.2834 ± 0.0018\n",
      "\n",
      "K = 20:\n",
      "  Precision@20: 0.1355 ± 0.0009\n",
      "  Recall@20   : 0.2872 ± 0.0020\n",
      "  Hit Rate@20 : 0.8678 ± 0.0026\n",
      "  NDCG@20     : 0.2842 ± 0.0016\n",
      "\n",
      "======================================================================\n",
      "TASK 2: BUNDLE COMPLETION\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RESULTS:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "K = 5:\n",
      "  Precision@5: 0.2424 ± 0.0018\n",
      "  Recall@5   : 0.1421 ± 0.0016\n",
      "  Hit Rate@5 : 0.6817 ± 0.0036\n",
      "  NDCG@5     : 0.3032 ± 0.0022\n",
      "\n",
      "K = 10:\n",
      "  Precision@10: 0.1864 ± 0.0012\n",
      "  Recall@10   : 0.2085 ± 0.0018\n",
      "  Hit Rate@10 : 0.7945 ± 0.0032\n",
      "  NDCG@10     : 0.2834 ± 0.0018\n",
      "\n",
      "K = 20:\n",
      "  Precision@20: 0.1355 ± 0.0009\n",
      "  Recall@20   : 0.2872 ± 0.0020\n",
      "  Hit Rate@20 : 0.8678 ± 0.0026\n",
      "  NDCG@20     : 0.2842 ± 0.0016\n",
      "\n",
      "======================================================================\n",
      "TASK 2: BUNDLE COMPLETION\n",
      "======================================================================\n",
      "Evaluating on 62,936 users...\n",
      "Evaluating on 62,936 users...\n",
      "  Progress: 5,000/62,936 users...\n",
      "  Progress: 5,000/62,936 users...\n",
      "  Progress: 10,000/62,936 users...\n",
      "  Progress: 10,000/62,936 users...\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"COMPREHENSIVE EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Task 1: Next-Game Purchase Prediction\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TASK 1: NEXT-GAME PURCHASE PREDICTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "task1_summary, task1_raw = evaluate_next_game_recommender(\n",
    "    next_game_recommender, \n",
    "    test_df, \n",
    "    k_values=[5, 10, 20]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"RESULTS:\")\n",
    "print(\"-\" * 70)\n",
    "for k in [5, 10, 20]:\n",
    "    metrics = task1_summary[k]\n",
    "    print(f\"\\nK = {k}:\")\n",
    "    print(f\"  Precision@{k}: {metrics['precision']['mean']:.4f} ± {metrics['precision']['ci']:.4f}\")\n",
    "    print(f\"  Recall@{k}   : {metrics['recall']['mean']:.4f} ± {metrics['recall']['ci']:.4f}\")\n",
    "    print(f\"  Hit Rate@{k} : {metrics['hit_rate']['mean']:.4f} ± {metrics['hit_rate']['ci']:.4f}\")\n",
    "    print(f\"  NDCG@{k}     : {metrics['ndcg']['mean']:.4f} ± {metrics['ndcg']['ci']:.4f}\")\n",
    "\n",
    "# Task 2: Bundle Completion\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TASK 2: BUNDLE COMPLETION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "task2_summary, task2_raw = evaluate_bundle_completion(\n",
    "    bundle_completion_recommender,\n",
    "    test_df,\n",
    "    k_values=[5, 10, 20]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"RESULTS:\")\n",
    "print(\"-\" * 70)\n",
    "for k in [5, 10, 20]:\n",
    "    metrics = task2_summary[k]\n",
    "    print(f\"\\nK = {k}:\")\n",
    "    print(f\"  Hit Rate@{k}        : {metrics['hit_rate']['mean']:.4f} ± {metrics['hit_rate']['ci']:.4f}\")\n",
    "    print(f\"  Bundle Precision@{k}: {metrics['bundle_precision']['mean']:.4f} ± {metrics['bundle_precision']['ci']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EVALUATION COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01fcdd1",
   "metadata": {},
   "source": [
    "## 8. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72fa5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "fig.suptitle('Steam Game Recommender System - Performance Summary', fontsize=20, fontweight='bold')\n",
    "\n",
    "# 1. Task 1: Hit Rate across K values\n",
    "ax1 = axes[0, 0]\n",
    "k_vals = [5, 10, 20]\n",
    "hr_means = [task1_summary[k]['hit_rate']['mean'] for k in k_vals]\n",
    "hr_cis = [task1_summary[k]['hit_rate']['ci'] for k in k_vals]\n",
    "ax1.bar(range(len(k_vals)), hr_means, yerr=hr_cis, capsize=5, color='green', alpha=0.8)\n",
    "ax1.set_title('Task 1: Hit Rate@K (Next-Game Prediction)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('K')\n",
    "ax1.set_ylabel('Hit Rate')\n",
    "ax1.set_xticks(range(len(k_vals)))\n",
    "ax1.set_xticklabels([f'K={k}' for k in k_vals])\n",
    "ax1.set_ylim(0, max(hr_means) * 1.2)\n",
    "for i, (mean, ci) in enumerate(zip(hr_means, hr_cis)):\n",
    "    ax1.text(i, mean + ci + 0.02, f'{mean:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# 2. Task 1: All metrics at K=10\n",
    "ax2 = axes[0, 1]\n",
    "k = 10\n",
    "metrics_names = ['Precision', 'Recall', 'Hit Rate', 'NDCG']\n",
    "metrics_values = [\n",
    "    task1_summary[k]['precision']['mean'],\n",
    "    task1_summary[k]['recall']['mean'],\n",
    "    task1_summary[k]['hit_rate']['mean'],\n",
    "    task1_summary[k]['ndcg']['mean']\n",
    "]\n",
    "metrics_cis = [\n",
    "    task1_summary[k]['precision']['ci'],\n",
    "    task1_summary[k]['recall']['ci'],\n",
    "    task1_summary[k]['hit_rate']['ci'],\n",
    "    task1_summary[k]['ndcg']['ci']\n",
    "]\n",
    "colors = ['blue', 'orange', 'green', 'red']\n",
    "ax2.bar(range(len(metrics_names)), metrics_values, yerr=metrics_cis, capsize=5, color=colors, alpha=0.8)\n",
    "ax2.set_title(f'Task 1: All Metrics @ K={k}', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_xticks(range(len(metrics_names)))\n",
    "ax2.set_xticklabels(metrics_names)\n",
    "ax2.set_ylim(0, max(metrics_values) * 1.3)\n",
    "for i, (val, ci) in enumerate(zip(metrics_values, metrics_cis)):\n",
    "    ax2.text(i, val + ci + 0.01, f'{val:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# 3. Task 2: Bundle Completion Performance\n",
    "ax3 = axes[1, 0]\n",
    "k_vals = [5, 10, 20]\n",
    "hr_means_t2 = [task2_summary[k]['hit_rate']['mean'] for k in k_vals]\n",
    "bp_means = [task2_summary[k]['bundle_precision']['mean'] for k in k_vals]\n",
    "hr_cis_t2 = [task2_summary[k]['hit_rate']['ci'] for k in k_vals]\n",
    "bp_cis = [task2_summary[k]['bundle_precision']['ci'] for k in k_vals]\n",
    "\n",
    "x = np.arange(len(k_vals))\n",
    "width = 0.35\n",
    "ax3.bar(x - width/2, hr_means_t2, width, yerr=hr_cis_t2, capsize=5, label='Hit Rate', color='teal', alpha=0.8)\n",
    "ax3.bar(x + width/2, bp_means, width, yerr=bp_cis, capsize=5, label='Bundle Precision', color='orange', alpha=0.8)\n",
    "ax3.set_title('Task 2: Bundle Completion Performance', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('K')\n",
    "ax3.set_ylabel('Score')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels([f'K={k}' for k in k_vals])\n",
    "ax3.legend()\n",
    "ax3.set_ylim(0, max(max(hr_means_t2), max(bp_means)) * 1.2)\n",
    "\n",
    "# 4. Summary Statistics\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "summary_text = f\"\"\"\n",
    "SUMMARY STATISTICS\n",
    "\n",
    "Dataset:\n",
    "  • Total Users: {len(user_to_idx):,}\n",
    "  • Total Games: {len(item_to_idx):,}\n",
    "  • Total Bundles: {len(bundle_to_idx):,}\n",
    "  • Training Interactions: {train_matrix.nnz:,}\n",
    "  • Test Interactions: {len(test_df):,}\n",
    "\n",
    "Best Results (K=10):\n",
    "  • Hit Rate: {task1_summary[10]['hit_rate']['mean']:.4f}\n",
    "  • NDCG: {task1_summary[10]['ndcg']['mean']:.4f}\n",
    "  • Precision: {task1_summary[10]['precision']['mean']:.4f}\n",
    "  • Recall: {task1_summary[10]['recall']['mean']:.4f}\n",
    "\n",
    "Model Configuration:\n",
    "  • Type: Hybrid (Bundle + Co-purchase)\n",
    "  • Alpha: 0.7 (70% similarity, 30% popularity)\n",
    "  • Device: {device}\n",
    "  • GPU Accelerated: {device.type != 'cpu'}\n",
    "\"\"\"\n",
    "ax4.text(0.1, 0.5, summary_text, fontsize=12, verticalalignment='center', \n",
    "         fontfamily='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(f'{model_outputs_dir}/final_evaluation_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Visualization saved to {model_outputs_dir}/final_evaluation_summary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1bed6b",
   "metadata": {},
   "source": [
    "## 9. Generate Sample Recommendations\n",
    "\n",
    "Demonstrate the recommender system with real examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_recommendations(user_idx, k=10):\n",
    "    \"\"\"\n",
    "    Get comprehensive recommendations for a user across all three tasks.\n",
    "    \"\"\"\n",
    "    # Get user info\n",
    "    user_id = idx_to_user.get(user_idx, f'user_{user_idx}')\n",
    "    owned_items = train_matrix[user_idx].nonzero()[1]\n",
    "    owned_game_ids = [idx_to_item[idx] for idx in owned_items[:10]]  # Show first 10\n",
    "    \n",
    "    result = {\n",
    "        'user_idx': int(user_idx),\n",
    "        'user_id': user_id,\n",
    "        'owned_games_count': len(owned_items),\n",
    "        'owned_games_sample': owned_game_ids,\n",
    "    }\n",
    "    \n",
    "    # Task 1: Next-game recommendations\n",
    "    task1_recs = next_game_recommender.recommend(user_idx, k=k)\n",
    "    result['next_game_recommendations'] = [\n",
    "        {'item_idx': int(item_idx), 'item_id': idx_to_item[item_idx], 'score': float(score)}\n",
    "        for item_idx, score in task1_recs\n",
    "    ]\n",
    "    \n",
    "    # Task 2: Bundle completion recommendations\n",
    "    partial_bundles = bundle_completion_recommender.get_partial_bundles(user_idx)\n",
    "    result['partial_bundles_count'] = len(partial_bundles)\n",
    "    \n",
    "    if partial_bundles:\n",
    "        task2_recs = bundle_completion_recommender.recommend(user_idx, k=k, min_ownership=0.3)\n",
    "        result['bundle_completion_recommendations'] = [\n",
    "            {'item_idx': int(item_idx), 'item_id': idx_to_item[item_idx], 'confidence': float(score)}\n",
    "            for item_idx, score in task2_recs\n",
    "        ]\n",
    "        result['top_partial_bundles'] = [\n",
    "            {\n",
    "                'bundle_idx': bundle['bundle_idx'],\n",
    "                'ownership_ratio': bundle['ownership_ratio'],\n",
    "                'owned_count': bundle['owned_count'],\n",
    "                'missing_count': bundle['missing_count']\n",
    "            }\n",
    "            for bundle in partial_bundles[:3]\n",
    "        ]\n",
    "    else:\n",
    "        result['bundle_completion_recommendations'] = []\n",
    "        result['top_partial_bundles'] = []\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Generate recommendations for sample users\n",
    "print(\"=\" * 70)\n",
    "print(\"SAMPLE RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Select diverse users (some with many games, some with few)\n",
    "test_users = test_df['user_idx'].unique()\n",
    "sample_size = min(5, len(test_users))\n",
    "sample_users = np.random.choice(test_users, size=sample_size, replace=False)\n",
    "\n",
    "sample_recommendations = []\n",
    "\n",
    "for user_idx in sample_users:\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    result = get_user_recommendations(user_idx, k=10)\n",
    "    sample_recommendations.append(result)\n",
    "    \n",
    "    print(f\"User: {result['user_id']} (owns {result['owned_games_count']} games)\")\n",
    "    print(f\"\\nOwned games (sample): {', '.join(result['owned_games_sample'][:5])}\")\n",
    "    \n",
    "    print(f\"\\nTask 1 - Top 5 Next-Game Recommendations:\")\n",
    "    for i, rec in enumerate(result['next_game_recommendations'][:5], 1):\n",
    "        print(f\"  {i}. {rec['item_id']} (score: {rec['score']:.3f})\")\n",
    "    \n",
    "    if result['bundle_completion_recommendations']:\n",
    "        print(f\"\\nTask 2 - Bundle Completion ({result['partial_bundles_count']} partial bundles):\")\n",
    "        for i, rec in enumerate(result['bundle_completion_recommendations'][:5], 1):\n",
    "            print(f\"  {i}. {rec['item_id']} (confidence: {rec['confidence']:.3f})\")\n",
    "        \n",
    "        print(f\"\\nTop Partial Bundles:\")\n",
    "        for i, bundle in enumerate(result['top_partial_bundles'], 1):\n",
    "            print(f\"  {i}. Bundle {bundle['bundle_idx']}: {bundle['ownership_ratio']*100:.1f}% owned \"\n",
    "                  f\"({bundle['owned_count']}/{bundle['owned_count']+bundle['missing_count']} games)\")\n",
    "    else:\n",
    "        print(f\"\\nTask 2 - No partial bundles found for this user\")\n",
    "\n",
    "# Save sample recommendations\n",
    "with open(f'{model_outputs_dir}/sample_recommendations.json', 'w') as f:\n",
    "    json.dump(sample_recommendations, f, indent=2)\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"✓ Sample recommendations saved to {model_outputs_dir}/sample_recommendations.json\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519143b8",
   "metadata": {},
   "source": [
    "## 10. Save Final Results and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a25e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SAVING FINAL RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save comprehensive evaluation results\n",
    "final_results = {\n",
    "    'task1_next_game_prediction': task1_summary,\n",
    "    'task2_bundle_completion': task2_summary,\n",
    "    'best_parameters': {\n",
    "        'alpha': 0.7,\n",
    "        'similarity_matrix': 'combined',\n",
    "        'device': str(device)\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'n_users': len(user_to_idx),\n",
    "        'n_items': len(item_to_idx),\n",
    "        'n_bundles': len(bundle_to_idx),\n",
    "        'train_interactions': int(train_matrix.nnz),\n",
    "        'test_interactions': len(test_df),\n",
    "        'sparsity': float(1 - train_matrix.nnz / (train_matrix.shape[0] * train_matrix.shape[1]))\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{model_outputs_dir}/final_evaluation_results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2, default=float)\n",
    "\n",
    "print(f\"✓ Evaluation results saved to {model_outputs_dir}/final_evaluation_results.json\")\n",
    "\n",
    "# Save models\n",
    "models_to_save = {\n",
    "    'next_game_recommender': next_game_recommender,\n",
    "    'bundle_completion_recommender': bundle_completion_recommender,\n",
    "    'cross_bundle_recommender': cross_bundle_recommender\n",
    "}\n",
    "\n",
    "with open(f'{model_outputs_dir}/trained_models.pkl', 'wb') as f:\n",
    "    pickle.dump(models_to_save, f)\n",
    "\n",
    "print(f\"✓ Trained models saved to {model_outputs_dir}/trained_models.pkl\")\n",
    "\n",
    "# Create results summary table\n",
    "summary_df = pd.DataFrame({\n",
    "    'Metric': ['Precision@10', 'Recall@10', 'Hit Rate@10', 'NDCG@10'],\n",
    "    'Score': [\n",
    "        task1_summary[10]['precision']['mean'],\n",
    "        task1_summary[10]['recall']['mean'],\n",
    "        task1_summary[10]['hit_rate']['mean'],\n",
    "        task1_summary[10]['ndcg']['mean']\n",
    "    ],\n",
    "    'Confidence Interval': [\n",
    "        task1_summary[10]['precision']['ci'],\n",
    "        task1_summary[10]['recall']['ci'],\n",
    "        task1_summary[10]['hit_rate']['ci'],\n",
    "        task1_summary[10]['ndcg']['ci']\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary_df.to_csv(f'{model_outputs_dir}/final_summary.csv', index=False)\n",
    "print(f\"✓ Summary table saved to {model_outputs_dir}/final_summary.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL RESULTS SAVED!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c86b01",
   "metadata": {},
   "source": [
    "## 11. Usage Guide: How to Get Recommendations for Any User\n",
    "\n",
    "This section demonstrates how to use the trained models to get recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd9610",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"USAGE GUIDE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "usage_guide = \"\"\"\n",
    "HOW TO USE THE RECOMMENDER SYSTEM\n",
    "\n",
    "1. Get recommendations for a user by user_idx:\n",
    "   \n",
    "   recommendations = next_game_recommender.recommend(user_idx=0, k=10)\n",
    "   \n",
    "2. Get recommendations for a user by user_id:\n",
    "   \n",
    "   user_idx = user_to_idx['user_id_here']\n",
    "   recommendations = next_game_recommender.recommend(user_idx, k=10)\n",
    "   \n",
    "3. Get bundle completion recommendations:\n",
    "   \n",
    "   bundle_recs = bundle_completion_recommender.recommend(user_idx, k=10, min_ownership=0.3)\n",
    "   \n",
    "4. Find similar bundles:\n",
    "   \n",
    "   similar_bundles = cross_bundle_recommender.recommend(bundle_idx=0, k=5)\n",
    "   \n",
    "5. Use the helper function:\n",
    "   \n",
    "   result = get_user_recommendations(user_idx, k=10)\n",
    "   # Returns comprehensive recommendations across all three tasks\n",
    "\"\"\"\n",
    "\n",
    "print(usage_guide)\n",
    "\n",
    "# Example: Get recommendations for a random user\n",
    "example_user_idx = np.random.choice(test_df['user_idx'].unique())\n",
    "print(f\"\\nEXAMPLE: Recommendations for user {example_user_idx}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "recs = next_game_recommender.recommend(example_user_idx, k=5)\n",
    "print(f\"Top 5 next-game recommendations:\")\n",
    "for i, (item_idx, score) in enumerate(recs, 1):\n",
    "    print(f\"  {i}. {idx_to_item[item_idx]} (score: {score:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd27d94",
   "metadata": {},
   "source": [
    "## 12. Summary and Key Findings\n",
    "\n",
    "### Model Performance:\n",
    "- **Hit Rate@10**: 79.5% (Combined model)\n",
    "- **NDCG@10**: High ranking quality for relevant recommendations\n",
    "- **GPU Acceleration**: Significant speedup on Apple Silicon (MPS) and NVIDIA GPUs\n",
    "\n",
    "### Key Insights:\n",
    "1. **Bundle relationships provide stronger signals** than pure collaborative filtering\n",
    "2. **Partial bundle ownership** (e.g., owns 3/5 games) is a strong purchase indicator\n",
    "3. **Hybrid approach** (combining bundle similarity + co-purchase + popularity) performs best\n",
    "4. **Optimal alpha=0.7**: 70% similarity weight, 30% popularity weight\n",
    "\n",
    "### Three Recommendation Tasks:\n",
    "1. **Next-Game Purchase Prediction** - Predict games users will purchase next\n",
    "2. **Bundle Completion** - Complete partially owned bundles\n",
    "3. **Cross-Bundle Discovery** - Find similar bundles for cross-promotion\n",
    "\n",
    "### Technical Highlights:\n",
    "- GPU-accelerated inference with PyTorch\n",
    "- Sparse matrix operations for efficiency\n",
    "- 95% confidence intervals for statistical significance\n",
    "- Comprehensive evaluation metrics (Precision, Recall, Hit Rate, NDCG)\n",
    "\n",
    "**The models are now ready to generate personalized game recommendations!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
